{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl \n",
    "#mt_filt = hl.read_matrix_table(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 15:01:07 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'f0' as type str (user-supplied)\n",
      "  Loading field 'f1' as type int32 (user-supplied)\n",
      "  Loading field 'f2' as type int32 (user-supplied)\n",
      "  Loading field 'f3' as type str (user-supplied)\n",
      "  Loading field 'f4' as type str (user-supplied)\n",
      "  Loading field 'f5' as type str (not specified)\n"
     ]
    }
   ],
   "source": [
    "# coding region\n",
    "bed_file = hl.import_bed('gs://schema2/data/variant_qc/3.1_hl_filter-genotypes-schema-gnomad/0.2.1/grch38.gencode.v29.p8.merged.merged_by_exonid.cds.protein_coding.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema variants \n",
    "mt = hl.read_matrix_table('gs://schema2/data/variant_qc/3.1_hl_filter-genotypes-schema-gnomad/0.2.1/schema2-gnomad.common.mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204879"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bed_file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7318, 346787)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter HGDP genomes to exome sequencing regions - if region as a file \n",
    "\n",
    "# read in region file into a list\n",
    "with hl.utils.hadoop_open(file_path) as f: \n",
    "    file = [line.rstrip('\\n') for line in f]\n",
    "    \n",
    "# capture and broadcast the list as an expression\n",
    "file_list = hl.literal(file)\n",
    "\n",
    "# filter HGDP+TGP mt to only the regions in list \"file\"  \n",
    "mt_filtered = mt.filter_rows(~file_list.contains(mt['chrom']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter HGDP genomes to SCHEMA shared variants????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge HGDP genomes with SCHEMA exomes\n",
    "# code in Lindo's nb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pruning\n",
    "# remove correlated variants \n",
    "pruned = hl.ld_prune(mt.GT, r2=0.1, bp_window_size=500000) # ~113 min to run  \n",
    "mt_var_pru_filt = mt.filter_rows(hl.is_defined(pruned[mt.row_key])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate related and unrelated samples for PCA\n",
    "relatedness_ht = hl.pc_relate(mt_var_pru_filt.GT, min_individual_maf=0.05, min_kinship=0.05, statistics='kin', k=20).key_by()\n",
    "\n",
    "# identify related individuals in pairs to remove - returns a list of sample IDs (~2hr & 22 min to run) - previous one took ~13min\n",
    "related_samples_to_remove = hl.maximal_independent_set(relatedness_ht.i, relatedness_ht.j, False)\n",
    "\n",
    "# using sample IDs (col_key of the matrixTable), pick out the samples that are not found in 'related_samples_to_remove' (had 'False' values for the comparison)  \n",
    "# subset the mt to those only \n",
    "mt_unrel = mt_var_pru_filt.filter_cols(hl.is_defined(related_samples_to_remove[mt_var_pru_filt.col_key]), keep=False) \n",
    "\n",
    "# do the same as above but this time for the samples with 'True' values (found in 'related_samples_to_remove')  \n",
    "mt_rel = mt_var_pru_filt.filter_cols(hl.is_defined(related_samples_to_remove[mt_var_pru_filt.col_key]), keep=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA function \n",
    "def run_pca(mt: hl.MatrixTable, reg_name:str, out_prefix: str, overwrite: bool = False):\n",
    "    \"\"\"\n",
    "    Runs PCA on a dataset\n",
    "    :param mt: dataset to run PCA on\n",
    "    :param reg_name: region name for saving output purposes\n",
    "    :param out_prefix: path for where to save the outputs\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    pca_evals, pca_scores, pca_loadings = hl.hwe_normalized_pca(mt.GT, k=20, compute_loadings=True)\n",
    "    pca_mt = mt.annotate_rows(pca_af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2)\n",
    "    pca_loadings = pca_loadings.annotate(pca_af=pca_mt.rows()[pca_loadings.key].pca_af)\n",
    "    pca_scores = pca_scores.transmute(**{f'PC{i}': pca_scores.scores[i - 1] for i in range(1, 21)})\n",
    "    \n",
    "    pca_scores.export(out_prefix + reg_name + '_scores.txt.bgz')  # save individual-level genetic region PCs\n",
    "    pca_loadings.write(out_prefix + reg_name + '_loadings.ht', overwrite)  # save PCA loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to projected related samples \n",
    "#if running on GCS, need to add \"--packages gnomad\" when starting a cluster in order for the import to work  \n",
    "from gnomad.sample_qc.ancestry import *\n",
    "\n",
    "def project_individuals(pca_loadings, project_mt, reg_name:str, out_prefix: str, overwrite: bool = False):\n",
    "    \"\"\"\n",
    "    Project samples into predefined PCA space\n",
    "    :param pca_loadings: existing PCA space - unrelated samples \n",
    "    :param project_mt: matrixTable of data to project - related samples \n",
    "    :param reg_name: region name for saving output purposes\n",
    "    :param project_prefix: path for where to save PCA projection outputs\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ht_projections = pc_project(project_mt, pca_loadings)  \n",
    "    ht_projections = ht_projections.transmute(**{f'PC{i}': ht_projections.scores[i - 1] for i in range(1, 21)}) \n",
    "    ht_projections.export(out_prefix + reg_name + '_projected_scores.txt.bgz') # save output \n",
    "    #return ht_projections # return to user  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pca function on unrelated samples \n",
    "# for global pca   \n",
    "run_pca(mt_unrel, 'global', 'gs://hgdp-1kg/hgdp_tgp/pca_preoutlier/', False)\n",
    "\n",
    "loadings = hl.read_table('gs://hgdp-1kg/hgdp_tgp/pca_preoutlier/global_loadings.ht') # read in the PCA loadings that were obtained from 'run_pca' function \n",
    "project_individuals(loadings, mt_rel, 'global', 'gs://hgdp-1kg/hgdp_tgp/pca_preoutlier/', False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pca function on related samples "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
